{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"fraud_oracle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing bad age values\n",
    "df = df[df['Age'] != 0]\n",
    "\n",
    "#removing policy number and year\n",
    "df = df.drop([\"PolicyNumber\",\"Year\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting a number value for each month and day of the week\n",
    "month_to_number = {\n",
    "    'January': 1, 'Jan': 1,\n",
    "    'February': 2, 'Feb': 2,\n",
    "    'March': 3, 'Mar': 3,\n",
    "    'April': 4, 'Apr': 4,\n",
    "    'May': 5,\n",
    "    'June': 6, 'Jun': 6,\n",
    "    'July': 7, 'Jul': 7,\n",
    "    'August': 8, 'Aug': 8,\n",
    "    'September': 9, 'Sep': 9,\n",
    "    'October': 10, 'Oct': 10,\n",
    "    'November': 11, 'Nov': 11,\n",
    "    'December': 12, 'Dec': 12\n",
    "}\n",
    "day_to_number = {\n",
    "    'Monday': 1, 'Mon': 1,\n",
    "    'Tuesday': 2, 'Tue': 2,\n",
    "    'Wednesday': 3, 'Wed': 3,\n",
    "    'Thursday': 4, 'Thu': 4,\n",
    "    'Friday': 5, 'Fri': 5,\n",
    "    'Saturday': 6, 'Sat': 6,\n",
    "    'Sunday': 7, 'Sun': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the months and days values to numerical values\n",
    "df['Month'] = df['Month'].map(month_to_number)\n",
    "df['MonthClaimed'] = df['MonthClaimed'].map(month_to_number)\n",
    "df['DayOfWeek'] = df['DayOfWeek'].map(day_to_number)\n",
    "df['DayOfWeekClaimed'] = df['DayOfWeekClaimed'].map(day_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# List of column names to encode\n",
    "columns_to_encode = ['AccidentArea','Sex','MaritalStatus','Fault','VehicleCategory','PastNumberOfClaims','PoliceReportFiled','WitnessPresent','AgentType','BasePolicy']\n",
    "\n",
    "# LabelEncoder for each selected column\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode the selected columns\n",
    "for column in columns_to_encode:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "    label_encoders[column] = label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# columns to be one-hot encoded\n",
    "columns_to_encode = ['Make', 'PolicyType', 'VehiclePrice','Days_Policy_Accident','Days_Policy_Claim','AgeOfVehicle','AgeOfPolicyHolder','AddressChange_Claim','NumberOfCars','NumberOfSuppliments']\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(df[['Make', 'PolicyType', 'VehiclePrice','Days_Policy_Accident','Days_Policy_Claim','AgeOfVehicle','AgeOfPolicyHolder','AddressChange_Claim','NumberOfCars','NumberOfSuppliments']])\n",
    "df_encoded = pd.DataFrame(encoded_data.toarray(), columns=encoder.get_feature_names_out(['Make', 'PolicyType', 'VehiclePrice','Days_Policy_Accident','Days_Policy_Claim','AgeOfVehicle','AgeOfPolicyHolder','AddressChange_Claim','NumberOfCars','NumberOfSuppliments']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Make', 'PolicyType', 'VehiclePrice','Days_Policy_Accident','Days_Policy_Claim','AgeOfVehicle','AgeOfPolicyHolder','AddressChange_Claim','NumberOfCars','NumberOfSuppliments'],axis=1)\n",
    "df = df.reset_index()\n",
    "df = df.drop('index',axis=1)\n",
    "df_encoded = df_encoded.reset_index()\n",
    "df_encoded = df_encoded.drop('index',axis=1)\n",
    "\n",
    "#concat both data frames\n",
    "concatenated_df = pd.concat([df, df_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import TomekLinks, RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, brier_score_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "y = np.array(concatenated_df[\"FraudFound_P\"])\n",
    "x = concatenated_df.drop(\"FraudFound_P\",axis=1)\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "xgboost = xgb.XGBClassifier()\n",
    "lightgbm = lgb.LGBMClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets (adjust the test_size and random_state as needed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smote = SMOTE(random_state=42,sampling_strategy=\"minority\")\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train your models on the training data\n",
    "random_forest.fit(X_smote, y_smote)\n",
    "decision_tree.fit(X_smote, y_smote)\n",
    "xgboost.fit(X_smote, y_smote)\n",
    "lightgbm.fit(X_smote, y_smote)\n",
    "\n",
    "sampling_technique = \"SMOTE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RandomOverSampler\n",
    "random_oversampler = RandomOverSampler(sampling_strategy=\"minority\", random_state=42)\n",
    "\n",
    "# Resample the training data using RandomOverSampler\n",
    "X_resampled, y_resampled = random_oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train your models on the training data\n",
    "random_forest.fit(X_resampled, y_resampled)\n",
    "decision_tree.fit(X_resampled, y_resampled)\n",
    "xgboost.fit(X_resampled, y_resampled)\n",
    "lightgbm.fit(X_resampled, y_resampled)\n",
    "\n",
    "sampling_technique = \"Random oversampler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an ADASYN oversampler\n",
    "adasyn = ADASYN(sampling_strategy=\"minority\", random_state=42)\n",
    "\n",
    "# Resample the training data using ADASYN\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train your models on the training data\n",
    "random_forest.fit(X_adasyn, y_adasyn)\n",
    "decision_tree.fit(X_adasyn, y_adasyn)\n",
    "xgboost.fit(X_adasyn, y_adasyn)\n",
    "lightgbm.fit(X_adasyn, y_adasyn)\n",
    "\n",
    "sampling_technique = \"ADASYN\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a BorderlineSMOTE oversampler\n",
    "borderline_smote = BorderlineSMOTE(sampling_strategy=\"minority\", random_state=42)\n",
    "\n",
    "# Resample the training data using BorderlineSMOTE\n",
    "X_borderline_smote, y_borderline_smote = borderline_smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train your models on the training data\n",
    "random_forest.fit(X_borderline_smote, y_borderline_smote)\n",
    "decision_tree.fit(X_borderline_smote, y_borderline_smote)\n",
    "xgboost.fit(X_borderline_smote, y_borderline_smote)\n",
    "lightgbm.fit(X_borderline_smote, y_borderline_smote)\n",
    "\n",
    "sampling_technique = \"borderline smote\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ADASYN oversampler\n",
    "Random_undersampler = RandomUnderSampler(sampling_strategy=\"not majority\")\n",
    "\n",
    "# Resample the training data using ADASYN\n",
    "x_random_undersampler, y_random_undersampler = Random_undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train your models on the training data\n",
    "random_forest.fit(x_random_undersampler, y_random_undersampler)\n",
    "decision_tree.fit(x_random_undersampler, y_random_undersampler)\n",
    "xgboost.fit(x_random_undersampler, y_random_undersampler)\n",
    "lightgbm.fit(x_random_undersampler, y_random_undersampler)\n",
    "\n",
    "sampling_technique = \"random undersampler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rf_predictions = random_forest.predict(X_test)\n",
    "dt_predictions = decision_tree.predict(X_test)\n",
    "xgb_predictions = xgboost.predict(X_test)\n",
    "lgb_predictions = lightgbm.predict(X_test)\n",
    "\n",
    "# Calculate F1 score, precision, recall, and accuracy for each model\n",
    "rf_f1 = f1_score(y_test, rf_predictions)\n",
    "rf_precision = precision_score(y_test, rf_predictions)\n",
    "rf_recall = recall_score(y_test, rf_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_brier_score = brier_score_loss(y_test, rf_predictions)\n",
    "\n",
    "dt_f1 = f1_score(y_test, dt_predictions)\n",
    "dt_precision = precision_score(y_test, dt_predictions)\n",
    "dt_recall = recall_score(y_test, dt_predictions)\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "dt_brier_score = brier_score_loss(y_test, dt_predictions)\n",
    "\n",
    "xgb_f1 = f1_score(y_test, xgb_predictions)\n",
    "xgb_precision = precision_score(y_test, xgb_predictions)\n",
    "xgb_recall = recall_score(y_test, xgb_predictions)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
    "xgb_brier_score = brier_score_loss(y_test,xgb_predictions)\n",
    "\n",
    "lgb_f1 = f1_score(y_test, lgb_predictions)\n",
    "lgb_precision = precision_score(y_test, lgb_predictions)\n",
    "lgb_recall = recall_score(y_test, lgb_predictions)\n",
    "lgb_accuracy = accuracy_score(y_test, lgb_predictions)\n",
    "lgb_brier_score = brier_score_loss(y_test, lgb_predictions)\n",
    "\n",
    "models = ['Random Forest', 'Decision Tree', 'XGBoost', 'LightGBM']\n",
    "accuracies = [rf_accuracy, dt_accuracy, xgb_accuracy, lgb_accuracy]\n",
    "f1_scores = [rf_f1, dt_f1, xgb_f1, lgb_f1]\n",
    "precisions = [rf_precision, dt_precision, xgb_precision, lgb_precision]\n",
    "recalls = [rf_recall, dt_recall, xgb_recall, lgb_recall]\n",
    "brier_scores = [rf_brier_score,dt_brier_score,xgb_brier_score,lgb_brier_score]\n",
    "\n",
    "# Create a list of lists for tabulate\n",
    "data = []\n",
    "for model, accuracy, f1, precision, recall, brier_score in zip(models, accuracies, f1_scores, precisions, recalls, brier_scores):\n",
    "    data.append([model, accuracy, f1, precision, recall, brier_score ,sampling_technique])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "models = ['Random Forest', 'Decision Tree', 'XGBoost', 'LightGBM']\n",
    "accuracies = [rf_accuracy, dt_accuracy, xgb_accuracy, lgb_accuracy]\n",
    "f1_scores = [rf_f1, dt_f1, xgb_f1, lgb_f1]\n",
    "precisions = [rf_precision, dt_precision, xgb_precision, lgb_precision]\n",
    "recalls = [rf_recall, dt_recall, xgb_recall, lgb_recall]\n",
    "brier_scores = [rf_brier_score, dt_brier_score, xgb_brier_score, lgb_brier_score]\n",
    "\n",
    "# Set up the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar positions\n",
    "bar_positions = np.arange(len(models))\n",
    "bar_width = 0.2\n",
    "\n",
    "# Plotting each metric for all models\n",
    "bars1 = ax.bar(bar_positions - 2 * bar_width, accuracies, bar_width, label='Accuracy')\n",
    "bars2 = ax.bar(bar_positions - bar_width, f1_scores, bar_width, label='F1 Score')\n",
    "bars3 = ax.bar(bar_positions, precisions, bar_width, label='Precision')\n",
    "bars4 = ax.bar(bar_positions + bar_width, recalls, bar_width, label='Recall')\n",
    "bars5 = ax.bar(bar_positions + 2 * bar_width, brier_scores, bar_width, label='Brier Score')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Performance Measures')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(bar_positions)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "\n",
    "# Adding value labels above each bar\n",
    "def add_value_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate('{}'.format(round(height, 2)),\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_value_labels(bars1)\n",
    "add_value_labels(bars2)\n",
    "add_value_labels(bars3)\n",
    "add_value_labels(bars4)\n",
    "add_value_labels(bars5)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
